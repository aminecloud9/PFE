{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NSLKDD_Originaldata_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16_X2LMa1V7ENkqAtbATRAiCkL9sf9fXy",
      "authorship_tag": "ABX9TyPhOTretD/WIvPsKQImvq5D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminecloud9/PFE/blob/main/NSLKDD_Originaldata_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zubbW2t0qkI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1b6614-3af3-41fd-f2a4-b5b528a6fa84"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.datasets import imdb\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import (precision_score, recall_score,\n",
        "                             f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import h5py\n",
        "from keras import callbacks\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from numpy import where\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "import time\n",
        "from imblearn.under_sampling import CondensedNearestNeighbour"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybE0wIioxC50"
      },
      "source": [
        "pip install git+https://github.com/artemmavrin/focal-loss.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idL_NlX4xXNa"
      },
      "source": [
        "pip install focal-loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px30HHOq6ihg"
      },
      "source": [
        "Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGP9ArVErwIu"
      },
      "source": [
        "#data=pd.read_csv('/content/drive/MyDrive/CICIDS2017_multi_class_StandardScaler_NormalsationResults.csv')\n",
        "#train_data = pd.read_csv('/content/drive/MyDrive/KDDTrain+.csv', header = None,nrows=1) # read just first line for columns\n",
        "#columns = train_data.columns.tolist() # get the columns\n",
        "#cols_to_use = columns[:len(columns)-1] \n",
        "train_data=pd.read_csv('/content/drive/MyDrive/KDDTrain+.csv',header=None)\n",
        "train_data = train_data.iloc[:, :-1]# drop the last one\n",
        "#train_data = train_data.iloc[:, 1:]# drop the first one\n",
        "test_data=pd.read_csv('/content/drive/MyDrive/KDDTest+.csv',header=None)\n",
        "test_data = test_data.iloc[:, :-1]# drop the last one\n",
        "#train_data = train_data.iloc[:, 1:]# drop the first one"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "TnahHtjMyELy",
        "outputId": "8011316b-ad77-4164-9841-5e5f00942cf7"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "      <td>491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>150</td>\n",
              "      <td>25</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>26</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>dos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>232</td>\n",
              "      <td>8153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>30</td>\n",
              "      <td>255</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>199</td>\n",
              "      <td>420</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.09</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125968</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>184</td>\n",
              "      <td>25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>25</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>dos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125969</th>\n",
              "      <td>8</td>\n",
              "      <td>udp</td>\n",
              "      <td>private</td>\n",
              "      <td>SF</td>\n",
              "      <td>105</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>244</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125970</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>smtp</td>\n",
              "      <td>SF</td>\n",
              "      <td>2231</td>\n",
              "      <td>384</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>30</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125971</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>klogin</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>8</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>dos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125972</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>77</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>125973 rows Ã— 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    1         2   3     4     5   ...    36    37    38    39    40      41\n",
              "0        0  tcp  ftp_data  SF   491     0  ...  0.00  0.00  0.00  0.05  0.00  normal\n",
              "1        0  udp     other  SF   146     0  ...  0.00  0.00  0.00  0.00  0.00  normal\n",
              "2        0  tcp   private  S0     0     0  ...  0.00  1.00  1.00  0.00  0.00     dos\n",
              "3        0  tcp      http  SF   232  8153  ...  0.04  0.03  0.01  0.00  0.01  normal\n",
              "4        0  tcp      http  SF   199   420  ...  0.00  0.00  0.00  0.00  0.00  normal\n",
              "...     ..  ...       ...  ..   ...   ...  ...   ...   ...   ...   ...   ...     ...\n",
              "125968   0  tcp   private  S0     0     0  ...  0.00  1.00  1.00  0.00  0.00     dos\n",
              "125969   8  udp   private  SF   105   145  ...  0.00  0.00  0.00  0.00  0.00  normal\n",
              "125970   0  tcp      smtp  SF  2231   384  ...  0.00  0.72  0.00  0.01  0.00  normal\n",
              "125971   0  tcp    klogin  S0     0     0  ...  0.00  1.00  1.00  0.00  0.00     dos\n",
              "125972   0  tcp  ftp_data  SF   151     0  ...  0.00  0.00  0.00  0.00  0.00  normal\n",
              "\n",
              "[125973 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BEplQGjzx15"
      },
      "source": [
        "Data nemerisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5_5KUiyzxSp"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "enc = OrdinalEncoder()\n",
        "train_data[[1]] = enc.fit_transform(train_data[[1]])\n",
        "test_data[[1]] = enc.fit_transform(test_data[[1]])\n",
        "\n",
        "train_data[[2]] = enc.fit_transform(train_data[[2]])\n",
        "test_data[[2]] = enc.fit_transform(test_data[[2]])\n",
        "\n",
        "train_data[[3]] = enc.fit_transform(train_data[[3]])\n",
        "test_data[[3]] = enc.fit_transform(test_data[[3]])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaDvNxT97K_X"
      },
      "source": [
        "Train and test data formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbi5xXhgsu1K"
      },
      "source": [
        "train_X = train_data.values[:,:-1]\n",
        "train_y = pd.factorize(train_data.values[:,-1])\n",
        "test_X = test_data.values[:,:-1]\n",
        "test_y = pd.factorize(test_data.values[:,-1])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcwfilLCl5t3"
      },
      "source": [
        "Data scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7DFNv1M6H5G"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "train_X=scaler.fit_transform(train_X)\n",
        "test_X = scaler.fit_transform(test_X)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDEg_-8EJha4"
      },
      "source": [
        "Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "id": "oBF721-WJlxs",
        "outputId": "ca8c47cf-2399-482b-f707-467724c418af"
      },
      "source": [
        "# Oversample and plot imbalanced dataset with SMOTE\n",
        "# summarize distribution\n",
        "counter = Counter(train_y[0])\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(train_y) * 100\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()\n",
        "# transform the dataset\n",
        "oversample = SMOTE(sampling_strategy={2:11656 , 4:11656 })\n",
        "under = RandomUnderSampler(sampling_strategy={0:11656, 1:11656 })\n",
        "steps = [('u', under),('o',oversample)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "train_X, train_y = pipeline.fit_resample(train_X, train_y[0])\n",
        "# summarize the new class distribution\n",
        "counter = Counter(train_y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "\trow_ix = where(train_y == label)[0]\n",
        "\tpyplot.scatter(train_X[row_ix, 0], train_X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class=0, n=67343 (3367150.000%)\n",
            "Class=1, n=45927 (2296350.000%)\n",
            "Class=2, n=995 (49750.000%)\n",
            "Class=3, n=11656 (582800.000%)\n",
            "Class=4, n=52 (2600.000%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD6CAYAAABDPiuvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASuklEQVR4nO3dbYxd5Xnu8f9VO7QoLbEpUwt5rGOkWqlcpBAYgatURz2gmAGqmA8tArX1CFnxkXB6EqlS4/QLKjQS+dI0llIkK7jYPWmom7bCSkzdESGqjnQMHgKFgBN5SkEeC/A0Y6ApaiLSux/243bHzMseM7O34/n/pK291v08a+17KYFr1svepKqQJK1sPzXoBiRJg2cYSJIMA0mSYSBJwjCQJGEYSJLoIQySfDDJs12vt5J8KsnlScaTnGjva9v8JNmTZDLJc0mu7drXWJt/IslYV/26JM+3bfYkyfIcriRpNlnM9wySrAJOATcAu4CZqnogyW5gbVV9OsmtwO8Ct7Z5X6iqG5JcDkwAI0ABTwPXVdWZJE8B/wd4EjgM7Kmqx+br5YorrqiNGzcu7mglaQV7+umn/6WqhmYbW73Ifd0E/FNVvZJkG/Brrb4f+CbwaWAbcKA6KXM0yZokV7a541U1A5BkHBhN8k3gsqo62uoHgNuBecNg48aNTExMLLJ9SVq5krwy19hi7xncCXylLa+rqlfb8mvAura8HjjZtc1Uq81Xn5qlLknqk57DIMklwMeAvzp3rJ0FLPvvWiTZmWQiycT09PRyf5wkrRiLOTO4BfhWVb3e1l9vl39o76db/RSwoWu74Vabrz48S/1dqmpvVY1U1cjQ0KyXvSRJ52ExYXAX/32JCOAQcPaJoDHg0a769vZU0RbgzXY56QiwNcna9uTRVuBIG3sryZb2FNH2rn1JkvqgpxvISd4PfBT4313lB4CDSXYArwB3tPphOk8STQJvA3cDVNVMkvuBY23efWdvJgP3AA8Dl9K5cTzvzWNJ0tJa1KOlF5KRkZHyaSJJ6l2Sp6tqZLYxv4EsSTIMJEmGgSSJxX8D+aKwcffXB93Cknn5gdsG3YKki4BnBpIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCTRYxgkWZPkq0m+k+R4kl9JcnmS8SQn2vvaNjdJ9iSZTPJckmu79jPW5p9IMtZVvy7J822bPUmy9IcqSZpLr2cGXwD+rqp+CfgQcBzYDTxeVZuAx9s6wC3ApvbaCTwIkORy4F7gBuB64N6zAdLmfLxru9H3dliSpMVYMAySfAD4n8BDAFX1w6p6A9gG7G/T9gO3t+VtwIHqOAqsSXIlcDMwXlUzVXUGGAdG29hlVXW0qgo40LUvSVIf9HJmcBUwDfxZkmeSfCnJ+4F1VfVqm/MasK4trwdOdm0/1Wrz1admqb9Lkp1JJpJMTE9P99C6JKkXvYTBauBa4MGq+jDwb/z3JSEA2l/0tfTt/biq2ltVI1U1MjQ0tNwfJ0krRi9hMAVMVdWTbf2rdMLh9XaJh/Z+uo2fAjZ0bT/cavPVh2epS5L6ZMEwqKrXgJNJPthKNwEvAoeAs08EjQGPtuVDwPb2VNEW4M12OekIsDXJ2nbjeCtwpI29lWRLe4poe9e+JEl9sLrHeb8LfDnJJcBLwN10guRgkh3AK8Adbe5h4FZgEni7zaWqZpLcDxxr8+6rqpm2fA/wMHAp8Fh7SZL6pKcwqKpngZFZhm6aZW4Bu+bYzz5g3yz1CeDqXnqRJC09v4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJNFjGCR5OcnzSZ5NMtFqlycZT3Kiva9t9STZk2QyyXNJru3az1ibfyLJWFf9urb/ybZtlvpAJUlzW8yZwf+qqmuqaqSt7wYer6pNwONtHeAWYFN77QQehE54APcCNwDXA/eeDZA25+Nd242e9xFJkhbtvVwm2gbsb8v7gdu76geq4yiwJsmVwM3AeFXNVNUZYBwYbWOXVdXRqirgQNe+JEl90GsYFPD3SZ5OsrPV1lXVq235NWBdW14PnOzadqrV5qtPzVJ/lyQ7k0wkmZienu6xdUnSQlb3OO9Xq+pUkl8AxpN8p3uwqipJLX17P66q9gJ7AUZGRpb98yRppejpzKCqTrX308Df0rnm/3q7xEN7P92mnwI2dG0+3Grz1YdnqUuS+mTBMEjy/iQ/d3YZ2Ap8GzgEnH0iaAx4tC0fAra3p4q2AG+2y0lHgK1J1rYbx1uBI23srSRb2lNE27v2JUnqg14uE60D/rY97bka+Iuq+rskx4CDSXYArwB3tPmHgVuBSeBt4G6AqppJcj9wrM27r6pm2vI9wMPApcBj7SVJ6pMFw6CqXgI+NEv9e8BNs9QL2DXHvvYB+2apTwBX99CvJGkZ+A1kSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CSRO+/TaSLxMbdXx90C0vm5QduG3QL0kXDMwNJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKLCIMkq5I8k+Rrbf2qJE8mmUzyl0kuafWfbuuTbXxj1z4+0+rfTXJzV3201SaT7F66w5Mk9WIxZwafBI53rX8O+HxV/SJwBtjR6juAM63++TaPJJuBO4FfBkaBP20Bswr4InALsBm4q82VJPVJT2GQZBi4DfhSWw9wI/DVNmU/cHtb3tbWaeM3tfnbgEeq6gdV9c/AJHB9e01W1UtV9UPgkTZXktQnvZ4Z/Anw+8B/tPWfB96oqnfa+hSwvi2vB04CtPE32/z/qp+zzVx1SVKfLBgGSX4dOF1VT/ehn4V62ZlkIsnE9PT0oNuRpItGL2cGHwE+luRlOpdwbgS+AKxJcvY/mzkMnGrLp4ANAG38A8D3uuvnbDNX/V2qam9VjVTVyNDQUA+tS5J6sWAYVNVnqmq4qjbSuQH8jar6LeAJ4DfatDHg0bZ8qK3Txr9RVdXqd7anja4CNgFPAceATe3ppEvaZxxakqOTJPVk9cJT5vRp4JEkfwQ8AzzU6g8Bf55kEpih8y93quqFJAeBF4F3gF1V9SOAJJ8AjgCrgH1V9cJ76EuStEiLCoOq+ibwzbb8Ep0ngc6d8+/Ab86x/WeBz85SPwwcXkwvkqSl4zeQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiR6CIMkP5PkqST/mOSFJH/Y6lcleTLJZJK/THJJq/90W59s4xu79vWZVv9ukpu76qOtNplk99IfpiRpPr2cGfwAuLGqPgRcA4wm2QJ8Dvh8Vf0icAbY0ebvAM60+ufbPJJsBu4EfhkYBf40yaokq4AvArcAm4G72lxJUp8sGAbV8f22+r72KuBG4Kutvh+4vS1va+u08ZuSpNUfqaofVNU/A5PA9e01WVUvVdUPgUfaXElSn/R0z6D9Bf8scBoYB/4JeKOq3mlTpoD1bXk9cBKgjb8J/Hx3/Zxt5qpLkvqkpzCoqh9V1TXAMJ2/5H9pWbuaQ5KdSSaSTExPTw+iBUm6KC3qaaKqegN4AvgVYE2S1W1oGDjVlk8BGwDa+AeA73XXz9lmrvpsn7+3qkaqamRoaGgxrUuS5tHL00RDSda05UuBjwLH6YTCb7RpY8CjbflQW6eNf6OqqtXvbE8bXQVsAp4CjgGb2tNJl9C5yXxoKQ5OktSb1QtP4Upgf3vq56eAg1X1tSQvAo8k+SPgGeChNv8h4M+TTAIzdP7lTlW9kOQg8CLwDrCrqn4EkOQTwBFgFbCvql5YsiOUJC1owTCoqueAD89Sf4nO/YNz6/8O/OYc+/os8NlZ6oeBwz30K0laBn4DWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEmihzBIsiHJE0leTPJCkk+2+uVJxpOcaO9rWz1J9iSZTPJckmu79jXW5p9IMtZVvy7J822bPUmyHAcrSZpdL2cG7wC/V1WbgS3AriSbgd3A41W1CXi8rQPcAmxqr53Ag9AJD+Be4AbgeuDeswHS5ny8a7vR935okqReLRgGVfVqVX2rLf8rcBxYD2wD9rdp+4Hb2/I24EB1HAXWJLkSuBkYr6qZqjoDjAOjbeyyqjpaVQUc6NqXJKkPFnXPIMlG4MPAk8C6qnq1Db0GrGvL64GTXZtNtdp89alZ6rN9/s4kE0kmpqenF9O6JGkePYdBkp8F/hr4VFW91T3W/qKvJe7tXapqb1WNVNXI0NDQcn+cJK0YPYVBkvfRCYIvV9XftPLr7RIP7f10q58CNnRtPtxq89WHZ6lLkvqkl6eJAjwEHK+qP+4aOgScfSJoDHi0q769PVW0BXizXU46AmxNsrbdON4KHGljbyXZ0j5re9e+JEl9sLqHOR8Bfgd4PsmzrfYHwAPAwSQ7gFeAO9rYYeBWYBJ4G7gboKpmktwPHGvz7quqmbZ8D/AwcCnwWHtJkvpkwTCoqv8HzPXc/02zzC9g1xz72gfsm6U+AVy9UC+SpOXhN5AlSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJKA1YNuQFJ/bNz99UG3sGRefuC2Qbdw0fHMQJK0cBgk2ZfkdJJvd9UuTzKe5ER7X9vqSbInyWSS55Jc27XNWJt/IslYV/26JM+3bfYkyVIfpCRpfr2cGTwMjJ5T2w08XlWbgMfbOsAtwKb22gk8CJ3wAO4FbgCuB+49GyBtzse7tjv3syRJy2zBMKiqfwBmzilvA/a35f3A7V31A9VxFFiT5ErgZmC8qmaq6gwwDoy2scuq6mhVFXCga1+SpD4533sG66rq1bb8GrCuLa8HTnbNm2q1+epTs9RnlWRnkokkE9PT0+fZuiTpXO/5BnL7i76WoJdePmtvVY1U1cjQ0FA/PlKSVoTzDYPX2yUe2vvpVj8FbOiaN9xq89WHZ6lLkvrofMPgEHD2iaAx4NGu+vb2VNEW4M12OekIsDXJ2nbjeCtwpI29lWRLe4poe9e+JEl9suCXzpJ8Bfg14IokU3SeCnoAOJhkB/AKcEebfhi4FZgE3gbuBqiqmST3A8favPuq6uxN6XvoPLF0KfBYe0mS+mjBMKiqu+YYummWuQXsmmM/+4B9s9QngKsX6kOStHz8BrIkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJCygMkowm+W6SySS7B92PJK0kqwfdAECSVcAXgY8CU8CxJIeq6sXBdqaLzcbdXx90C0vi5QduG3QLushcKGcG1wOTVfVSVf0QeATYNuCeJGnFuFDCYD1wsmt9qtUkSX1wQVwm6lWSncDOtvr9JN8dZD8LuAL4l+X+kHxuuT/hvC378XvsFyT/f9+H438P/sdcAxdKGJwCNnStD7faj6mqvcDefjX1XiSZqKqRQfcxKCv5+D32lXns8JN9/BfKZaJjwKYkVyW5BLgTODTgniRpxbggzgyq6p0knwCOAKuAfVX1woDbkqQV44IIA4CqOgwcHnQfS+gn4nLWMlrJx++xr1w/scefqhp0D5KkAbtQ7hlIkgbIMFgGK/mnNZLsS3I6ybcH3Uu/JdmQ5IkkLyZ5IcknB91TvyT5mSRPJfnHdux/OOie+i3JqiTPJPnaoHs5H4bBEuv6aY1bgM3AXUk2D7arvnoYGB10EwPyDvB7VbUZ2ALsWkH/2/8AuLGqPgRcA4wm2TLgnvrtk8DxQTdxvgyDpbeif1qjqv4BmBl0H4NQVa9W1bfa8r/S+RfDivgmfXV8v62+r71WzA3JJMPAbcCXBt3L+TIMlp4/rSGSbAQ+DDw52E76p10meRY4DYxX1Yo5duBPgN8H/mPQjZwvw0BaYkl+Fvhr4FNV9dag++mXqvpRVV1D5xcErk9y9aB76ockvw6crqqnB93Le2EYLL2eflpDF6ck76MTBF+uqr8ZdD+DUFVvAE+wcu4dfQT4WJKX6VwWvjHJ/x1sS4tnGCw9f1pjhUoS4CHgeFX98aD76ackQ0nWtOVL6fy3Sb4z2K76o6o+U1XDVbWRzj/v36iq3x5wW4tmGCyxqnoHOPvTGseBgyvppzWSfAX4/8AHk0wl2THonvroI8Dv0PnL8Nn2unXQTfXJlcATSZ6j8wfReFX9RD5iuVL5DWRJkmcGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRLwnwZ4uoNwAqz3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 11656, 1: 11656, 2: 11656, 3: 11656, 4: 11656})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt19bhSSN_-L"
      },
      "source": [
        "# summarize distribution\n",
        "counter = Counter(train_y[0])\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(train_y) * 100\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()\n",
        "# transform the dataset\n",
        "undersample = CondensedNearestNeighbour(n_neighbors=1)(sampling_strategy={0:11656, 1:11656 })\n",
        "train_X, train_y = pipeline.fit_resample(train_X, train_y[0])\n",
        "# summarize the new class distribution\n",
        "counter = Counter(train_y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "\trow_ix = where(train_y == label)[0]\n",
        "\tpyplot.scatter(train_X[row_ix, 0], train_X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y14yBaZlm9LP"
      },
      "source": [
        "reshape input to be [samples, time steps, features]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7FOxrdJ2tye"
      },
      "source": [
        "import keras\n",
        "#X_train = np.reshape(data.values[:,:-1].astype('float32'), (data.values[:,:-1].shape[0], 1, data.values[:,:-1].shape[1]))\n",
        "X_train = np.reshape(train_X.astype('float32'), (train_X.shape[0], 1, train_X.shape[1]))\n",
        "X_test = np.reshape(test_X.astype('float32'), (test_X.shape[0], 1, test_X.shape[1]))\n",
        "#y_train = keras.utils.to_categorical(pd.factorize(data.values[:,77])[0],15)\n",
        "y_train = keras.utils.to_categorical(train_y[0],5)\n",
        "y_train = y_train.astype('int')\n",
        "#y_train = np.reshape(y_train,(y_train.shape[0],1,y_train.shape[1]))\n",
        "y_test = keras.utils.to_categorical(test_y[0],5)\n",
        "y_test = y_test.astype('int')\n",
        "#y_test = np.reshape(y_test,(y_test.shape[0],1,y_test.shape[1]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bDpNSDynNOa",
        "outputId": "8bf76a67-b4ed-447d-f9e3-d9ef545e5b8f"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125973, 1, 41)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX2VddNf7iyt"
      },
      "source": [
        "Define the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "Z2X1EbkTFiow",
        "outputId": "643eef50-c6d1-434a-a0db-faba9f0b922e"
      },
      "source": [
        "#train_object_num=len(train_data)\n",
        "#print(test[0])\n",
        "#model training\n",
        "batch_size = 128\n",
        "lrate = 0.3\n",
        "DROPOUTRATE = 0.1\n",
        "model=Sequential()\n",
        "model.add(LSTM(X_train.shape[2],input_dim=X_train.shape[2],return_sequences=True,kernel_initializer='uniform',activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(LSTM(32,kernel_initializer='uniform',return_sequences=True,activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(LSTM(32,kernel_initializer='uniform',return_sequences=True,activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "#model.add(Dense(256,activation='relu'))\n",
        "#model.add(Dropout(DROPOUTRATE))\n",
        "#model.add(Dense(128,activation='relu'))\n",
        "#model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(y_train.shape[2],activation='sigmoid'))\n",
        "opt = SGD(lr=lrate)\n",
        "model.compile(loss='binary_crossentropy',optimizer='ADAM',metrics=['accuracy'])\n",
        "model.summary()\n",
        "start_time = time.time()\n",
        "history = model.fit(X_train,y_train,validation_split=.3,epochs=100,batch_size=batch_size,verbose=1)\n",
        "finish_time = time.time() - start_time\n",
        "#model.save(\"/content/drive/My Drive/model_NSL-KDD_scaled_Multiclass_valsplit.3_bs1024_100ep.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, None, 41)          13612     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, None, 41)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 32)          9472      \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, None, 32)          8320      \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, None, 64)          2112      \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, None, 64)          0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, None, 16)          1040      \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, None, 5)           85        \n",
            "=================================================================\n",
            "Total params: 34,641\n",
            "Trainable params: 34,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "689/689 [==============================] - 9s 7ms/step - loss: 0.3016 - accuracy: 0.7181 - val_loss: 0.0287 - val_accuracy: 0.9748\n",
            "Epoch 2/100\n",
            "167/689 [======>.......................] - ETA: 2s - loss: 0.0347 - accuracy: 0.9720"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-abdf6fcf3fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mfinish_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#model.save(\"/content/drive/My Drive/model_NSL-KDD_scaled_Multiclass_valsplit.3_bs1024_100ep.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moFJO80m0D9v"
      },
      "source": [
        "saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieGpV2zYXZwV"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/NSL-KDD_42norm_results_5Dense_po_Dropout_200epoch_1024batch_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdRVMFrQSrR"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqAFEhU4_CMH"
      },
      "source": [
        "42 col pca 80% : b_s=256 epochs= 300 Lstm(32,32)->Dense(256,128,64,ytrain.shape(2))   ->   accuracy = 62.8%\n",
        "\n",
        "\n",
        "24 col normalisÃ© : b_s=1024 epochs= 100 Lstm(32,32)->Dense(256,128,64,16,ytrain.shape(2))   ->   accuracy = 83.73%\n",
        "24 col pca 80% : b_s=1024 epochs= 100 Lstm(32,32)->Dense(256,128,64,16,ytrain.shape(2))   ->   accuracy = 40.28%\n",
        "42 col normalisÃ© : b_s=1024 epochs= 100 Lstm(32,32)->Dense(256,128,64,16,ytrain.shape(2))   ->   accuracy = 48.52%\n",
        "42 col pca 80% : b_s=1024 epochs= 100 Lstm(32,32)->Dense(256,128,64,16,ytrain.shape(2))   ->   accuracy = 45.22%\n",
        "24 col pca 80% : b_s=1024 epochs= 100 Lstm(32,32)->Dense(64,16,ytrain.shape(2))   ->   accuracy = 42.58%\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GXF4BE1aiTS"
      },
      "source": [
        "# focal loss with multi label\n",
        "def focal_loss(classes_num, gamma=2., alpha=.25, e=0.1):\n",
        "    # classes_num contains sample number of each classes\n",
        "    def focal_loss_fixed(target_tensor, prediction_tensor):\n",
        "        '''\n",
        "        prediction_tensor is the output tensor with shape [None, 100], where 100 is the number of classes\n",
        "        target_tensor is the label tensor, same shape as predcition_tensor\n",
        "        '''\n",
        "        #1# get focal loss with no balanced weight which presented in paper function (4)\n",
        "        zeros = array_ops.zeros_like(prediction_tensor, dtype=prediction_tensor.dtype)\n",
        "        one_minus_p = array_ops.where(np.max(target_tensor,zeros), target_tensor - prediction_tensor, zeros)\n",
        "        FT = -1 * (one_minus_p ** gamma) * tf.log(tf.clip_by_value(prediction_tensor, 1e-8, 1.0))\n",
        "\n",
        "        #2# get balanced weight alpha\n",
        "        classes_weight = array_ops.zeros_like(prediction_tensor, dtype=prediction_tensor.dtype)\n",
        "\n",
        "        total_num = float(sum(classes_num))\n",
        "        classes_w_t1 = [ total_num / ff for ff in classes_num ]\n",
        "        sum_ = sum(classes_w_t1)\n",
        "        classes_w_t2 = [ ff/sum_ for ff in classes_w_t1 ]   #scale\n",
        "        classes_w_tensor = tf.convert_to_tensor(classes_w_t2, dtype=prediction_tensor.dtype)\n",
        "        classes_weight += classes_w_tensor\n",
        "\n",
        "        #alpha = array_ops.where(tf.greater(np.array(target_tensor, dtype=np.float32), zeros), classes_weight, zeros)\n",
        "\n",
        "        #3# get balanced focal loss\n",
        "        balanced_fl = alpha * FT\n",
        "        balanced_fl = tf.reduce_mean(balanced_fl)\n",
        "\n",
        "        #4# add other op to prevent overfit\n",
        "        # reference : https://spaces.ac.cn/archives/4493\n",
        "        nb_classes = len(classes_num)\n",
        "        fianal_loss = (1-e) * balanced_fl + e * K.categorical_crossentropy(K.ones_like(prediction_tensor)/nb_classes, prediction_tensor)\n",
        "\n",
        "        return fianal_loss\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5MC464vxwbw"
      },
      "source": [
        "def focal_loss(classes_num, gamma=2., alpha=.25, e=0.1):\n",
        "  def focal_loss_fixed(target_tensor, prediction_tensor):\n",
        "    tot_num = sum(classes_num)\n",
        "    alpha = classes_num/tot_num\n",
        "    mask = np.eye(alpha.shape[1])\n",
        "    loss = (prediction_tensor*mask - target_tensor*mask)*(prediction_tensor*mask - target_tensor*mask)\n",
        "    fianal_loss = sum(alpha*loss)\n",
        "    return fianal_loss\n",
        "return focal_loss_fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmRvSBvsbG2i"
      },
      "source": [
        "Xtr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpW4B3GT5_ac"
      },
      "source": [
        "batch_size= 128\n",
        "lrate = 0.1\n",
        "DROPOUTRATE = 0.1\n",
        "model = Sequential()\n",
        "model.add(Dense(X_train.shape[2], input_dim=X_train.shape[2], activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(768, activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(y_train.shape[2], activation='softmax'))\n",
        "\t# compile model\n",
        "opt = SGD(lr=lrate)\n",
        "#loss = categorical_focal_loss([67343,45927,995,11656,52])\n",
        "model.compile(loss= 'categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "# fit model\n",
        "model.summary()\n",
        "start_time = time.time()\n",
        "history = model.fit(X_train, y_train, validation_data = (X_test,y_test),batch_size=batch_size, epochs=10, verbose=1)\n",
        "finish_time = time.time() - start_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMlKyOzEB9F8",
        "outputId": "0baf0a77-90f6-47fe-e23c-7a2c9e95bd9f"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(GRU(128, input_shape=(1,41)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(48, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(48, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "history = model.fit(X_train, y_train,\n",
        "          epochs=30,\n",
        "          batch_size=64, validation_split=0.1, verbose=1)\n",
        "score = model.evaluate(X_test, y_test, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_7 (GRU)                  (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 48)                6192      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 48)                0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 48)                2352      \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 48)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 5)                 245       \n",
            "=================================================================\n",
            "Total params: 74,453\n",
            "Trainable params: 74,453\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "1772/1772 [==============================] - 10s 5ms/step - loss: 0.2729 - accuracy: 0.9182 - val_loss: 0.0429 - val_accuracy: 0.9857\n",
            "Epoch 2/30\n",
            "1772/1772 [==============================] - 7s 4ms/step - loss: 0.0544 - accuracy: 0.9822 - val_loss: 0.0339 - val_accuracy: 0.9894\n",
            "Epoch 3/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0445 - accuracy: 0.9852 - val_loss: 0.0286 - val_accuracy: 0.9906\n",
            "Epoch 4/30\n",
            "1772/1772 [==============================] - 7s 4ms/step - loss: 0.0384 - accuracy: 0.9871 - val_loss: 0.0265 - val_accuracy: 0.9903\n",
            "Epoch 5/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0342 - accuracy: 0.9877 - val_loss: 0.0239 - val_accuracy: 0.9917\n",
            "Epoch 6/30\n",
            "1772/1772 [==============================] - 7s 4ms/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 0.0241 - val_accuracy: 0.9919\n",
            "Epoch 7/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0317 - accuracy: 0.9891 - val_loss: 0.0220 - val_accuracy: 0.9931\n",
            "Epoch 8/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 0.0211 - val_accuracy: 0.9935\n",
            "Epoch 9/30\n",
            "1772/1772 [==============================] - 7s 4ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.0199 - val_accuracy: 0.9948\n",
            "Epoch 10/30\n",
            "1772/1772 [==============================] - 7s 4ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.0200 - val_accuracy: 0.9930\n",
            "Epoch 11/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.0193 - val_accuracy: 0.9936\n",
            "Epoch 12/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.0182 - val_accuracy: 0.9942\n",
            "Epoch 13/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.0180 - val_accuracy: 0.9948\n",
            "Epoch 14/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.0180 - val_accuracy: 0.9952\n",
            "Epoch 15/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.0182 - val_accuracy: 0.9941\n",
            "Epoch 16/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0171 - val_accuracy: 0.9945\n",
            "Epoch 17/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.0170 - val_accuracy: 0.9954\n",
            "Epoch 18/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0163 - val_accuracy: 0.9946\n",
            "Epoch 19/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0165 - val_accuracy: 0.9951\n",
            "Epoch 20/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.0157 - val_accuracy: 0.9957\n",
            "Epoch 21/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.0168 - val_accuracy: 0.9946\n",
            "Epoch 22/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 0.0152 - val_accuracy: 0.9955\n",
            "Epoch 23/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0152 - val_accuracy: 0.9952\n",
            "Epoch 24/30\n",
            "1772/1772 [==============================] - 7s 4ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0148 - val_accuracy: 0.9957\n",
            "Epoch 25/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.0151 - val_accuracy: 0.9952\n",
            "Epoch 26/30\n",
            "1772/1772 [==============================] - 8s 5ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0155 - val_accuracy: 0.9949\n",
            "Epoch 27/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.0145 - val_accuracy: 0.9955\n",
            "Epoch 28/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0155 - val_accuracy: 0.9956\n",
            "Epoch 29/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0146 - val_accuracy: 0.9954\n",
            "Epoch 30/30\n",
            "1772/1772 [==============================] - 8s 4ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 0.0148 - val_accuracy: 0.9960\n",
            "705/705 [==============================] - 1s 1ms/step - loss: 18.6579 - accuracy: 0.0743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "LYkmDTyOdMAB",
        "outputId": "3210c4ed-1061-49a3-e932-c776f5218827"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "loss, accuracy = model.evaluate(X_test,y_test)\n",
        "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
        "y_pred = model.predict_classes(X_test)\n",
        "target_names = ['Normal', 'Dos', 'Probe','R2L', 'U2R']\n",
        "print(classification_report(y_true = np.transpose(test_y[0]), y_pred = y_pred))\n",
        "#print(accuracy_score(y_true = np.transpose(test_y[0]), y_pred = y_pred))\n",
        "print(\"execution time :  \",finish_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "705/705 [==============================] - 1s 1ms/step - loss: 17.8440 - accuracy: 0.0780\n",
            "\n",
            "Loss: 17.84, Accuracy: 7.80%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.22      0.15      7458\n",
            "           1       0.01      0.01      0.01      9710\n",
            "           2       0.00      0.00      0.00      2421\n",
            "           3       0.00      0.00      0.00      2754\n",
            "           4       0.79      0.10      0.17       200\n",
            "\n",
            "    accuracy                           0.08     22543\n",
            "   macro avg       0.18      0.07      0.07     22543\n",
            "weighted avg       0.05      0.08      0.06     22543\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-3d17ca7fe33e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(accuracy_score(y_true = np.transpose(test_y[0]), y_pred = y_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"execution time :  \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinish_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'finish_time' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2w3Jk0odRYV",
        "outputId": "41fe6531-6f34-4122-bb5f-a90ef7fc8301"
      },
      "source": [
        "from keras.models import load_model\n",
        "#model = load_model('/content/drive/MyDrive/NSL-KDD_results_SimpleRNN_model.hdf5')\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
        "\n",
        "#print(\"--- %s seconds ---\",finish_time)\n",
        "y_pred = model.predict(X_train)\n",
        "#np.savetxt('/content/drive/MyDrive/NSL-KDD_results_SimpleRNN_predicted.txt', np.transpose([y_test,y_pred]), fmt='%s')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "705/705 [==============================] - 1s 1ms/step - loss: 18.6579 - accuracy: 0.0743\n",
            "\n",
            "Loss: 18.66, Accuracy: 7.43%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW_Mq1ZZS1Nc"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "# plot accuracy\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.title('lrate='+str(lrate), pad=-50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV49FqMAb9E6"
      },
      "source": [
        "\n",
        "# plot leoss\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.title('lrate='+str(lrate), pad=-50)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}