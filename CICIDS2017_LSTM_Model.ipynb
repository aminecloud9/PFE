{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CICIDS2017_LSTM_Model",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uleDWIWtAeo5MXZ2cAetU-XyUYyx5b8U",
      "authorship_tag": "ABX9TyOueJVgYtoLeD0qK8wm6xB4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminecloud9/PFE/blob/main/CICIDS2017_LSTM_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zubbW2t0qkI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105db9ea-e6ac-4fe6-e38a-2843efeb64bb"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras.datasets import imdb\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import (precision_score, recall_score,\n",
        "                             f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import h5py\n",
        "from keras import callbacks\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from numpy import where\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stUM1OvK4IWu"
      },
      "source": [
        "Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGP9ArVErwIu"
      },
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/globalData.csv')\n",
        "#Labels=pd.read_csv('/content/drive/MyDrive/CICIDS2017_Labels.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fPDhHCXHzE-"
      },
      "source": [
        "Y = data.values[:,-1]\n",
        "X = data.iloc[: , :-1]\n",
        "Y=pd.factorize(Y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "CwVE9hZec0tr",
        "outputId": "5654144f-d39c-46cc-b6ac-b528d9cdd854"
      },
      "source": [
        "# summarize distribution\n",
        "counter = Counter(Y[0])\n",
        "for k,v in counter.items():\n",
        "\tper = v / len(Y[0]) * 100\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class=0, n=2273097 (80.300%)\n",
            "Class=1, n=128027 (4.523%)\n",
            "Class=2, n=158930 (5.614%)\n",
            "Class=3, n=1966 (0.069%)\n",
            "Class=4, n=36 (0.001%)\n",
            "Class=5, n=1507 (0.053%)\n",
            "Class=6, n=652 (0.023%)\n",
            "Class=7, n=21 (0.001%)\n",
            "Class=8, n=7938 (0.280%)\n",
            "Class=9, n=5897 (0.208%)\n",
            "Class=10, n=5796 (0.205%)\n",
            "Class=11, n=5499 (0.194%)\n",
            "Class=12, n=231073 (8.163%)\n",
            "Class=13, n=10293 (0.364%)\n",
            "Class=14, n=11 (0.000%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "qT6RQrO4djwb",
        "outputId": "634067fc-5247-4762-f5fc-437ab45de64f"
      },
      "source": [
        "# Oversample and plot imbalanced dataset with SMOTE\n",
        "\n",
        "# define pipeline\n",
        "strategy = {0:652, 1:652, 2:652, 3:652, 5:652, 6:652, 8:652, 9:652, 10:652, 11:652, 12:652, 13:652 }\n",
        "oversample = SMOTE(sampling_strategy={4:652, 7:652, 14:652})\n",
        "under = RandomUnderSampler(sampling_strategy=strategy)\n",
        "steps = [('u', under),('o',oversample)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "# transform the dataset\n",
        "#oversample = SMOTE()\n",
        "X= np.nan_to_num(X)\n",
        "X, Y = pipeline.fit_resample(X, Y[0])\n",
        "# summarize the new class distribution\n",
        "counter = Counter(Y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "\trow_ix = where(Y == label)[0]\n",
        "\t#pyplot.scatter([row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "\n",
        "pyplot.bar(counter.keys(), counter.values())\n",
        "pyplot.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 652, 1: 652, 2: 652, 3: 652, 4: 652, 5: 652, 6: 652, 7: 652, 8: 652, 9: 652, 10: 652, 11: 652, 12: 652, 13: 652, 14: 652})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMBicShqKInv"
      },
      "source": [
        "Data scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY6EXElLKNJO",
        "outputId": "3bc81d70-2df6-45e2-82ed-44c8be60a971"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X= np.nan_to_num(X)\n",
        "X = scaler.fit_transform(X)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:808: RuntimeWarning: invalid value encountered in true_divide\n",
            "  X /= self.scale_\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG2uwLAl4cNK"
      },
      "source": [
        "Split dateset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-4aCMAUrn3D"
      },
      "source": [
        "#Import Module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, Y, \n",
        "                                                     train_size=0.7,\n",
        "                                                     test_size=0.3,\n",
        "                                                     random_state=122)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB9DHJQnvXWS"
      },
      "source": [
        "del(X)\n",
        "del(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz6HtUq1ZgEF"
      },
      "source": [
        "train_X= np.nan_to_num(train_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsRwlMa74-Po"
      },
      "source": [
        "train_X[:,pd.isna(train_X).any()].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7FOxrdJ2tye"
      },
      "source": [
        "# reshape input to be [samples, time steps, features]\n",
        "import keras\n",
        "\n",
        "#X_train = np.reshape(data.values[:,:-1].astype('float32'), (data.values[:,:-1].shape[0], 1, data.values[:,:-1].shape[1]))\n",
        "X_train = np.reshape(train_X.astype('float32'), (train_X.shape[0], 1, train_X.shape[1]))\n",
        "X_test = np.reshape(test_X.astype('float32'), (test_X.shape[0], 1, test_X.shape[1]))\n",
        "#y_train = keras.utils.to_categorical(pd.factorize(data.values[:,77])[0],15)\n",
        "test_y = pd.factorize(test_y)\n",
        "train_y = pd.factorize(train_y)\n",
        "y_train = keras.utils.to_categorical(train_y[0],train_y[1].shape[0])\n",
        "y_train = y_train.astype('int')\n",
        "y_train = np.reshape(y_train,(y_train.shape[0],1,y_train.shape[1]))\n",
        "y_test = keras.utils.to_categorical(test_y[0],train_y[1].shape[0])\n",
        "y_test = y_test.astype('int')\n",
        "y_test = np.reshape(y_test,(y_test.shape[0],1,y_test.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmi9FeVpM7z8"
      },
      "source": [
        "import time\n",
        "data_dim = X_train.shape[2]\n",
        "timesteps = 1\n",
        "num_classes = y_train.shape[2]\n",
        "batch_size = 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, stateful=False, batch_input_shape=(batch_size, timesteps, data_dim)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(50, return_sequences=True, stateful=False))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(50, stateful=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "start_time = time.time()\n",
        "model.fit(X_train, y_train,batch_size=batch_size, epochs=2, shuffle=False)\n",
        "finish_time = time.time() - start_time\n",
        "#model.save(\"/content/drive/My Drive/final_model_NSL-KDD_brute_Multiclass.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67sdryEkDuyz"
      },
      "source": [
        "from keras.layers.advanced_activations import LeakyReLU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6t3cskT3YMy",
        "outputId": "d81c2f7e-1c7b-4dda-8bb5-82a1bd953f4c"
      },
      "source": [
        "train_X[:,2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.30164428, -0.30291488, -0.30037367, ..., -0.29275002,\n",
              "       -0.30037367, -0.30164428])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "Z2X1EbkTFiow",
        "outputId": "2f0992d7-ebf5-49d7-9a58-69ba48c93c4a"
      },
      "source": [
        "#train_object_num=len(train_data)\n",
        "#print(test[0])\n",
        "#model training\n",
        "batch_size = 512\n",
        "model=Sequential()\n",
        "model.add(LSTM(X_train.shape[2],input_dim=X_train.shape[2],return_sequences=True,kernel_initializer='uniform',activation='relu'))\n",
        "model.add(LSTM(32,kernel_initializer='uniform',return_sequences=True,activation='relu'))\n",
        "#model.add(LSTM(128,kernel_initializer='uniform',return_sequences=True,activation='relu'))\n",
        "#model.add(Dense(256,activation='relu'))\n",
        "#model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "#model.add(Dense(16,activation='relu'))\n",
        "model.add(Dense(y_train.shape[2],activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='NADAM',metrics=['accuracy'])\n",
        "model.summary()\n",
        "start_time = time.time()\n",
        "history = model.fit(X_train,y_train,validation_split=.3,epochs=100,batch_size=batch_size,verbose=1)\n",
        "finish_time = time.time() - start_time\n",
        "#model.save(\"/content/drive/My Drive/model_CICIDS_brute_data_valsplit.3.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8773cc26c8ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BMxnJJH-46X",
        "outputId": "9e50705c-a22f-4b87-d253-cd9d101b16ad"
      },
      "source": [
        "print(np.any(np.isnan(X_train)))\n",
        "print(np.any(np.isnan(y_train)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J58S0Vi_4Nov",
        "outputId": "e8e715d8-de16-45d9-a18c-dc0ddfd7475a"
      },
      "source": [
        "batch_size= 16\n",
        "lrate = 0.01\n",
        "DROPOUTRATE = 0.3\n",
        "model = Sequential()\n",
        "model.add(Dense(X_train.shape[2], input_dim=X_train.shape[2], activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(768, activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(DROPOUTRATE))\n",
        "model.add(Dense(y_train.shape[2], activation='softmax'))\n",
        "\t# compile model\n",
        "opt = SGD(lr=lrate)\n",
        "#loss = categorical_focal_loss([67343,45927,995,11656,52])\n",
        "model.compile(loss= 'categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "# fit model\n",
        "model.summary()\n",
        "start_time = time.time()\n",
        "history = model.fit(X_train, y_train, validation_data = (X_test,y_test),batch_size=batch_size, epochs=100, verbose=1)\n",
        "finish_time = time.time() - start_time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_93 (Dense)             (None, 77)                6006      \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 1024)              79872     \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 768)               787200    \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 512)               393728    \n",
            "_________________________________________________________________\n",
            "dropout_67 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 15)                1935      \n",
            "=================================================================\n",
            "Total params: 1,432,965\n",
            "Trainable params: 1,432,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 77) for input KerasTensor(type_spec=TensorSpec(shape=(None, 77), dtype=tf.float32, name='dense_93_input'), name='dense_93_input', description=\"created by layer 'dense_93_input'\"), but it was called on an input with incompatible shape (None, 1, 77).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 77) for input KerasTensor(type_spec=TensorSpec(shape=(None, 77), dtype=tf.float32, name='dense_93_input'), name='dense_93_input', description=\"created by layer 'dense_93_input'\"), but it was called on an input with incompatible shape (None, 1, 77).\n",
            "426/428 [============================>.] - ETA: 0s - loss: 2.5673 - accuracy: 0.1407WARNING:tensorflow:Model was constructed with shape (None, 77) for input KerasTensor(type_spec=TensorSpec(shape=(None, 77), dtype=tf.float32, name='dense_93_input'), name='dense_93_input', description=\"created by layer 'dense_93_input'\"), but it was called on an input with incompatible shape (None, 1, 77).\n",
            "428/428 [==============================] - 8s 16ms/step - loss: 2.5660 - accuracy: 0.1413 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 2/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 1.6988 - accuracy: 0.4689 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 3/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 1.0048 - accuracy: 0.6542 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 4/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 0.7421 - accuracy: 0.7345 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 5/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 0.6367 - accuracy: 0.7660 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 6/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 0.5574 - accuracy: 0.7941 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 7/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 0.4575 - accuracy: 0.8307 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 8/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 0.4480 - accuracy: 0.8341 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 9/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 0.4180 - accuracy: 0.8422 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 10/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.3900 - accuracy: 0.8492 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 11/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.3904 - accuracy: 0.8440 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 12/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.3482 - accuracy: 0.8532 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 13/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.3474 - accuracy: 0.8618 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 14/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 0.3478 - accuracy: 0.8558 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 15/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 0.3280 - accuracy: 0.8569 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 16/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 0.3140 - accuracy: 0.8736 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 17/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2808 - accuracy: 0.8808 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 18/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2986 - accuracy: 0.8629 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 19/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.3072 - accuracy: 0.8623 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 20/100\n",
            "428/428 [==============================] - 7s 16ms/step - loss: 0.2956 - accuracy: 0.8706 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 21/100\n",
            "428/428 [==============================] - 7s 16ms/step - loss: 0.2991 - accuracy: 0.8755 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 22/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2718 - accuracy: 0.8792 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 23/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2740 - accuracy: 0.8814 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 24/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2814 - accuracy: 0.8805 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 25/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2693 - accuracy: 0.8810 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 26/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2599 - accuracy: 0.8825 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 27/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2694 - accuracy: 0.8808 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 28/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2409 - accuracy: 0.8936 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 29/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2630 - accuracy: 0.8782 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 30/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2507 - accuracy: 0.8852 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 31/100\n",
            "428/428 [==============================] - 7s 16ms/step - loss: 0.2467 - accuracy: 0.8799 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 32/100\n",
            "428/428 [==============================] - 7s 16ms/step - loss: 0.2511 - accuracy: 0.8779 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 33/100\n",
            "428/428 [==============================] - 7s 16ms/step - loss: 0.2526 - accuracy: 0.8809 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 34/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2443 - accuracy: 0.8869 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 35/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2443 - accuracy: 0.8867 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 36/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2377 - accuracy: 0.8941 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 37/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2449 - accuracy: 0.8866 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 38/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2449 - accuracy: 0.8885 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 39/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2491 - accuracy: 0.8795 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 40/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2419 - accuracy: 0.8931 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 41/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2365 - accuracy: 0.8941 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 42/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2383 - accuracy: 0.8857 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 43/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2212 - accuracy: 0.8870 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 44/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2225 - accuracy: 0.8911 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 45/100\n",
            "428/428 [==============================] - 6s 15ms/step - loss: 0.2294 - accuracy: 0.8896 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 46/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2319 - accuracy: 0.8838 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 47/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2346 - accuracy: 0.8883 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 48/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 49/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2255 - accuracy: 0.8886 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 50/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2352 - accuracy: 0.8901 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 51/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2268 - accuracy: 0.8895 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 52/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2321 - accuracy: 0.8746 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 53/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2202 - accuracy: 0.8906 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 54/100\n",
            "428/428 [==============================] - 7s 16ms/step - loss: 0.2188 - accuracy: 0.8970 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 55/100\n",
            "428/428 [==============================] - 7s 16ms/step - loss: 0.2277 - accuracy: 0.8938 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 56/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2242 - accuracy: 0.8937 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 57/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2330 - accuracy: 0.8885 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 58/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2038 - accuracy: 0.8932 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 59/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2039 - accuracy: 0.8992 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 60/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2052 - accuracy: 0.8936 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 61/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2114 - accuracy: 0.9008 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 62/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2160 - accuracy: 0.8900 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 63/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2179 - accuracy: 0.8929 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 64/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2243 - accuracy: 0.8887 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 65/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2205 - accuracy: 0.8943 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 66/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.1995 - accuracy: 0.8971 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 67/100\n",
            "428/428 [==============================] - 7s 16ms/step - loss: 0.2104 - accuracy: 0.9004 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 68/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2149 - accuracy: 0.8963 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 69/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2062 - accuracy: 0.8971 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 70/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2161 - accuracy: 0.8914 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 71/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2133 - accuracy: 0.8956 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 72/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2108 - accuracy: 0.8962 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 73/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2139 - accuracy: 0.8892 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 74/100\n",
            "428/428 [==============================] - 7s 16ms/step - loss: 0.2063 - accuracy: 0.8920 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 75/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2073 - accuracy: 0.8887 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 76/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2004 - accuracy: 0.8943 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 77/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2081 - accuracy: 0.8944 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 78/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2150 - accuracy: 0.8907 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 79/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.2133 - accuracy: 0.8908 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 80/100\n",
            "428/428 [==============================] - 7s 15ms/step - loss: 0.1971 - accuracy: 0.9015 - val_loss: nan - val_accuracy: 0.0641\n",
            "Epoch 81/100\n",
            "411/428 [===========================>..] - ETA: 0s - loss: 0.1896 - accuracy: 0.9040"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgFh6eY-RogJ",
        "outputId": "c76d5e85-6293-401b-8f73-e7e11acf6586"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train,y_train)\n",
        "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
        "y_pred = model.predict_classes(X_train)\n",
        "print(\"execution time :  \",finish_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "214/214 [==============================] - 1s 5ms/step - loss: 0.2206 - accuracy: 0.8926\n",
            "\n",
            "Loss: 0.22, Accuracy: 89.26%\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 77) for input KerasTensor(type_spec=TensorSpec(shape=(None, 77), dtype=tf.float32, name='dense_77_input'), name='dense_77_input', description=\"created by layer 'dense_77_input'\"), but it was called on an input with incompatible shape (None, 1, 77).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "execution time :   459.9898386001587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieGpV2zYXZwV"
      },
      "source": [
        "#saving model\n",
        "model.save(\"/content/drive/MyDrive/NSL-KDD_results_3LSTM_1Dense_20epoch_1batch_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xLvXBh0SyWh",
        "outputId": "f8852b13-9730-4c5e-c7c9-c5dbf08546e4"
      },
      "source": [
        "from keras.models import load_model\n",
        "#model = load_model('/content/drive/MyDrive/NSL-KDD_results_SimpleRNN_model.hdf5')\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
        "\n",
        "#print(\"--- %s seconds ---\",finish_time)\n",
        "y_pred = model.predict_classes(X_train)\n",
        "#np.savetxt('/content/drive/MyDrive/NSL-KDD_results_SimpleRNN_predicted.txt', np.transpose([y_test,y_pred]), fmt='%s')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "92/92 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.0641\n",
            "\n",
            "Loss: nan, Accuracy: 6.41%\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 77) for input KerasTensor(type_spec=TensorSpec(shape=(None, 77), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 1, 77).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}